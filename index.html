<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="This paper proposes a novel framework for human-robot collaboration (HRC) that integrates Robot Assistance Primitives (RAPs) with force-field guidance to enable versatile and safe shared-task collaboration in unstructured environments.">
  <meta name="keywords" content="Robot Assistance Primitives, HRC, shared tasks, impedance control, force-field guidance, AR-HMD">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Robot Assistance Primitives with Force-Field Guidance</title>

  <!-- (Optional) Google Analytics: remove or replace if not needed -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=YOUR-ID"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'YOUR-ID');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href="/">
      <span class="icon"><i class="fas fa-home"></i></span>
    </a>
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start">
      <!-- Add additional nav links if needed -->
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <h1 class="title is-1 publication-title">Robot Assistance Primitives with Force-Field Guidance</h1>
      <h2 class="subtitle is-5 has-text-grey">
            Published in <em>Robotics and Computer-Integrated Manufacturing</em> (2025)
      </h2>
      <p class="subtitle is-5 publication-authors">
        <a href="#">Sophokles Ktistakis</a><sup>1*</sup>, 
        <a href="#">Lucas Gimeno</a><sup>1</sup>, 
        <a href="#">Fatima-Zahra Laftissi</a><sup>2</sup>, 
        <a href="#">Alexis Hoss</a><sup>2</sup>, 
        <a href="#">Antonio De Donno</a><sup>2</sup>, 
        <a href="#">Mirko Meboldt</a><sup>1</sup>
      </p>
      <p class="publication-affiliations">
        <sup>1</sup>ETH Zurich &nbsp;|&nbsp; <sup>2</sup>Accenture Labs
      </p>
      <div class="buttons is-centered publication-links" style="margin-top: 1em;">
        <a href="https://www.sciencedirect.com/science/article/pii/S0736584525001152" class="button is-dark is-rounded">
          <span class="icon"><i class="fas fa-file-pdf"></i></span>
          <span>Paper</span>
        </a>
        <!-- <a href="https://doi.org/10.1016/j.rcim.2025.103061" class="button is-dark is-rounded">
          <span class="icon"><i class="fas fa-link"></i></span>
          <span>DOI</span>
        </a> -->
        <!-- <a href="https://github.com/your-repo" class="button is-dark is-rounded">
          <span class="icon"><i class="fab fa-github"></i></span>
          <span>Code</span>
        </a> -->
        <!-- Add more links as needed -->
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container has-text-centered">
      <!-- TODO: Add your project teaser video or image here -->
      <div class="notification is-light">
        <em>Teaser video placeholder</em>
      </div>
    </div>
  </div>
</section>

<section class="section" id="Abstract">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Abstract</h2>
    <div class="content has-text-justified">
      <p>This paper proposes a novel framework for human-robot collaboration (HRC) that addresses the critical need for robots to effectively collaborate with humans on shared tasks within unstructured and dynamic environments. While prior research focused on safety-related aspects, such as collision avoidance in shared workspaces, the task-oriented aspects of human-robot collaboration remain largely underexplored. To address this gap, our framework introduces Robot Assistance Primitives (RAPs), low-level robot actions that integrate both safety and task-related behaviors, enabling the robot to function as a collaborative “third hand” across physical and contactless interactions. A key component is an extension of impedance control with virtual force fields, unifying task guidance and collision avoidance. We leverage a state-of-the-art visual perception pipeline for real-time 3D scene understanding and an AR-HMD interface for multimodal task programming. We validate feasibility through technical experiments and conduct a user study on collaborative soldering and assembly, demonstrating significant improvements in efficiency and reduced cognitive load.</p>
    </div>
  </div>
</section>

<section class="section" id="Methods">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Methods</h2>
    <div class="content" style="text-align: center;">
      <img src="static/images/1-s2.0-S0736584525001152-gr2_lrg.jpg" 
           alt="Figure 1: System Overview" 
           style="max-width: 100%; height: auto; margin-top: 10px;">
      <p style="margin-top: 15px;">
        Our framework integrates three core components: (1) a real-time RGB-D visual perception pipeline for 3D scene understanding and object detection, (2) a multimodal AR interface for intuitive task programming via gaze, gestures, and speech, and (3) an impedance-based control scheme augmented with virtual force fields to unify task guidance and collision avoidance. These elements enable the execution of Robot Assistance Primitives (RAPs), versatile low-level actions that support both physical and contactless collaboration in unstructured environments</p>
    </div>
  </div>
</section>

<section class="section" id="Experiments">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Experiments</h2>
    <div class="content" style="text-align: center;">
      <img src="static/images/experiments.jpg" 
           alt="Experiment Overview" 
           style="max-width: 100%; height: auto; margin-top: 10px;">
      <p style="margin-top: 15px;">
       We conducted a user study with 22 participants performing a collaborative soldering and assembly task, comparing our robotic assistance framework to a manual baseline. The experimental group used Robot Assistance Primitives (RAPs) for PCB handling and assembly, while the control group relied on table-mounted fixtures. We evaluated task completion time, cognitive load (NASA TLX), user experience, and system safety across repeated trials to assess efficiency, usability, and collision avoidance.
    </div>
  </div>
</section>

  
<section class="hero is-small" id="Results">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Results</h2>
      <div id="results-carousel" class="carousel results-carousel">

        <!-- Item 1: Net Time per Run -->
        <div class="item">
          <img src="static/images/res_net_time.jpg" alt="Net Time per Run"/>
          <h2 class="subtitle has-text-centered">
            Task completion time across three runs for experimental (Robot) and control groups. The robotic system shows higher initial times but significant improvement with repeated runs.
          </h2>
        </div>

        <!-- Item 2: NASA TLX Scores -->
        <div class="item">
          <img src="static/images/res_tlx.jpg" alt="NASA TLX Results"/>
          <h2 class="subtitle has-text-centered">
            NASA TLX cognitive load comparison: mental and physical demand, effort, and frustration decreased for the robotic condition after repeated use, indicating improved usability and reduced workload.
          </h2>
        </div>

      </div>
    </div>
  </div>
</section>

<section class="section" id="Discussion">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Discussion</h2>
    <div class="content">
      <p>Discuss the implications, limitations, and future directions of your work.</p>
    </div>
  </div>
</section>

<section class="section" id="Conclusion">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Conclusion</h2>
    <div class="content">
      <p>Conclude with your main takeaways and potential impact.</p>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">BibTeX</h2>
    <pre><code>@article{ktistakis2025robot,
  author    = {Sophokles Ktistakis and Lucas Gimeno and Fatima-Zahra Laftissi and Alexis Hoss and Antonio {De Donno} and Mirko Meboldt},
  title     = {Robot assistance primitives with force-field guidance for shared task collaboration},
  journal   = {Robotics and Computer-Integrated Manufacturing},
  volume    = {96},
  year      = {2025},
  pages     = {103061},
  issn      = {0736-5845},     
  doi       = {https://doi.org/10.1016/j.rcim.2025.103061},
}
</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="content has-text-centered">
    <p>This website is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> license.</p>
  </div>
</footer>

  
<script src="./static/js/bulma-carousel.min.js"></script>
<script>
  document.addEventListener('DOMContentLoaded', () => {
    bulmaCarousel.attach('#results-carousel', {
      slidesToScroll: 1,
      slidesToShow:   1,
      loop:           true,
      autoplay:       true,
      pauseOnHover:   false,
    });
  });
</script>


  
</body>
</html>
